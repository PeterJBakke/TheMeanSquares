{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NCF_Net_TalentFox.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "bHfUHx4ygQZ9",
        "colab_type": "code",
        "outputId": "31589531-87c6-47a1-e4f5-bb65d0cc5764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1924
        }
      },
      "cell_type": "code",
      "source": [
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision torchtext\n",
        "import torch\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "!python -m spacy download en\n",
        "\n",
        "#####################################################\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "\n",
        "######################################################\n",
        "\n",
        "!python -m spacy download en\n",
        "!pip install msgpack==0.5.6\n",
        "!pip install spacy==2.0.0\n",
        "\n",
        "# WHAT YOU NEED TO DO\n",
        "# This piece of code will install everything to colab. However, you need to upload the csv files to your drive\n",
        "# to the My Drive/Colab Notebooks/data/' path. When you run this part, it will ask you to connect your own google drive\n",
        "# so you will need to give access to it - it seems i can't share my drive through Colab unfortunately\n",
        "\n",
        "# import torch.backends.cudnn as cudnn\n",
        "# cudnn.enabled = False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 37.4MB 69.5MB/s \n",
            "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): en-core-web-sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: spacy>=2.0.0a18 in /usr/local/lib/python3.6/dist-packages (from en-core-web-sm==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.2.8.2)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: cymem<1.32,>=1.30 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.31.2)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.11.0)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.35)\n",
            "Requirement already satisfied: msgpack-numpy in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.4.3.2)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (2017.4.5)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.9.6)\n",
            "Requirement already satisfied: thinc<6.11.0,>=6.10.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (6.10.3)\n",
            "Requirement already satisfied: ftfy<5.0.0,>=4.4.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (4.4.3)\n",
            "Requirement already satisfied: msgpack-python in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.5.6)\n",
            "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (2.18.4)\n",
            "Requirement already satisfied: murmurhash<0.29,>=0.28 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.28.0)\n",
            "Requirement already satisfied: msgpack>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from msgpack-numpy->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.5.6)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.10.11)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.9.0.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (4.28.1)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from ftfy<5.0.0,>=4.4.2->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<5.0.0,>=4.4.2->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.1.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (2018.11.29)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib->ftfy<5.0.0,>=4.4.2->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.5.1)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 37.4MB 58.5MB/s \n",
            "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): en-core-web-sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: spacy>=2.0.0a18 in /usr/local/lib/python3.6/dist-packages (from en-core-web-sm==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.11.0)\n",
            "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: thinc<6.11.0,>=6.10.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (6.10.3)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.9.6)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: msgpack-python in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.5.6)\n",
            "Requirement already satisfied: cymem<1.32,>=1.30 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.31.2)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.14.6)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (2017.4.5)\n",
            "Requirement already satisfied: murmurhash<0.29,>=0.28 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.28.0)\n",
            "Requirement already satisfied: msgpack-numpy in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.4.3.2)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.35)\n",
            "Requirement already satisfied: ftfy<5.0.0,>=4.4.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (4.4.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (2.18.4)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.2.8.2)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.10.11)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (4.28.1)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.9.0.1)\n",
            "Requirement already satisfied: msgpack<1.0.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.5.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<5.0.0,>=4.4.2->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.1.7)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from ftfy<5.0.0,>=4.4.2->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (2018.11.29)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (1.22)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.0->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib->ftfy<5.0.0,>=4.4.2->spacy>=2.0.0a18->en-core-web-sm==2.0.0) (0.5.1)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n",
            "Requirement already satisfied: msgpack==0.5.6 in /usr/local/lib/python3.6/dist-packages (0.5.6)\n",
            "Requirement already satisfied: spacy==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (0.9.6)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (0.2.8.2)\n",
            "Requirement already satisfied: murmurhash<0.29,>=0.28 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (0.28.0)\n",
            "Requirement already satisfied: ftfy<5.0.0,>=4.4.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (4.4.3)\n",
            "Requirement already satisfied: msgpack-numpy in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (0.4.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (1.11.0)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (2017.4.5)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (1.14.6)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (1.35)\n",
            "Requirement already satisfied: msgpack-python in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (0.5.6)\n",
            "Requirement already satisfied: cymem<1.32,>=1.30 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (1.31.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (2.18.4)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: thinc<6.11.0,>=6.10.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (6.10.3)\n",
            "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from ftfy<5.0.0,>=4.4.2->spacy==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<5.0.0,>=4.4.2->spacy==2.0.0) (0.1.7)\n",
            "Requirement already satisfied: msgpack>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from msgpack-numpy->spacy==2.0.0) (0.5.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.0.0) (2018.11.29)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.0.0) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.0.0) (2.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.0->spacy==2.0.0) (4.28.1)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.0->spacy==2.0.0) (1.10.11)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.0->spacy==2.0.0) (0.9.0.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib->ftfy<5.0.0,>=4.4.2->spacy==2.0.0) (0.5.1)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.0->spacy==2.0.0) (0.9.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hOeHBff7gXsa",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Data pre-processing file\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from torchtext import data, vocab\n",
        "import torch\n",
        "import spacy\n",
        "from random import randint\n",
        "\n",
        "spacy_en = spacy.load('en')\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class TalentFox:\n",
        "    \"\"\"\n",
        "    Class to handle the TalentFox data\n",
        "\n",
        "    Predict:\n",
        "    match_status\n",
        "\n",
        "    Columns for candidate:\n",
        "    candidate_city, candidate_state, candidate_country, candidate_title, candidate_birth_date,\n",
        "    candidate_current_fixed_salary, candidate_current_bonus_salary, candidate_in_job_market_since,\n",
        "    candidate_other_languages, candidate_is_looking_for_new_job, candidate_wish_2, candidate_wish_3, candidate_wish_1,\n",
        "    candidate_education, candidate_language_negotiative, candidate_language_basic, candidate_language_fluent,\n",
        "    candidate_highest_degree, candidate_career_type, candidate_industries, candidate_professions, candidate_resume,\n",
        "    candidate_feedback, candidate_professions_global, candidate_industries_global, candidate_relocation_ready,\n",
        "\n",
        "    Columns for job:\n",
        "    job_fixed_salary, job_bonus_salary, job_title, job_vacation_days, job_needed_experience, job_language,\n",
        "    job_description, job_daily_tasks_of_job, job_required_experience_of_candidate,\n",
        "    job_preferred_experience_of_candidate, job_preferred_education_of_candidate, job_max_candidate_age,\n",
        "    job_min_candidate_age, job_company_structure, job_language_skills_negotiative, job_language_skills_basic,\n",
        "    job_candidate_radius, job_candidate_relocation, job_city, job_state, job_country, job_time_model, job_max_salary,\n",
        "    job_questions_for_candidate, match_employer_feedback\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, batch_size=100):\n",
        "        print('Device: ' + str(device))\n",
        "\n",
        "        self.candidate_title = data.Field(sequential=True, lower=True, tokenize=tokenizer, include_lengths=True, use_vocab=True)\n",
        "        self.candidate_resume = data.Field(sequential=True, lower=True, tokenize=tokenizer, include_lengths=True, use_vocab=True)\n",
        "        self.job_title = data.Field(sequential=True, lower=True, tokenize=tokenizer, include_lengths=True, use_vocab=True)\n",
        "        self.job_description = data.Field(sequential=True, lower=True, tokenize=tokenizer, include_lengths=True, use_vocab=True)\n",
        "        self.match_status = data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "        self.train_set, self.validation_set = data.TabularDataset.splits(\n",
        "            path='./gdrive/My Drive/Colab Notebooks/data/TalentFox/',\n",
        "            train='train_data.csv',\n",
        "            validation='val_data.csv',\n",
        "            format='csv',\n",
        "            fields=[\n",
        "                ('index', None),\n",
        "                ('job_title', self.job_title),\n",
        "                ('job_description', self.job_description),\n",
        "                ('candidate_title', self.candidate_title),\n",
        "                ('candidate_resume', self.candidate_resume),\n",
        "                ('match_status', self.match_status)\n",
        "            ],\n",
        "            skip_header=True,\n",
        "        )\n",
        "\n",
        "        self.train_iter, self.validation_iter = data.BucketIterator.splits(\n",
        "            (self.train_set, self.validation_set),\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            device=device,\n",
        "            sort_key=lambda x: len(x.job_title),\n",
        "            sort_within_batch=True,\n",
        "            repeat=True)\n",
        "\n",
        "        self.match_status.build_vocab(self.train_set)\n",
        "        url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.de.vec'\n",
        "        self.job_title.build_vocab(self.train_set, vectors=vocab.Vectors('wiki.de.vec', url=url))\n",
        "        self.job_description.build_vocab(self.train_set, vectors=vocab.Vectors('wiki.de.vec', url=url))\n",
        "        self.candidate_title.build_vocab(self.train_set, vectors=vocab.Vectors('wiki.de.vec', url=url))\n",
        "        self.candidate_resume.build_vocab(self.train_set, vectors=vocab.Vectors('wiki.de.vec', url=url))\n",
        "        \n",
        "STOP_WORDS = {'(', ')', '/', 'm', 'w', '-', ' ', '.', '\\t'}\n",
        "\n",
        "def tokenizer(text):  # create a tokenizer function\n",
        "    tokens = [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "    tokens = list(filter(lambda token: token not in STOP_WORDS, tokens))\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nvDFnPDH7FTQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Model file\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.utils.rnn as rnn\n",
        "\n",
        "max_rating = 5.0\n",
        "min_rating = 0.5\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class TalentNetExperimental(nn.Module):\n",
        "    def __init__(self, job_title, job_description, candidate_title, candidate_resume, p1=0.2, p2=0.2, p3=0.2):\n",
        "        super(TalentNetExperimental, self).__init__()\n",
        "        self.job_title_vectors = job_title.vocab.vectors\n",
        "        self.job_title_num_embeddings = self.job_title_vectors.size()[0]\n",
        "        self.job_title_embedding_dim = self.job_title_vectors.size()[1]\n",
        "        \n",
        "        self.job_description_vectors = job_description.vocab.vectors\n",
        "        self.job_description_num_embeddings = self.job_description_vectors.size()[0]\n",
        "        self.job_description_embedding_dim = self.job_description_vectors.size()[1]\n",
        "\n",
        "        self.candidate_title_vectors = candidate_title.vocab.vectors\n",
        "        self.candidate_title_num_embeddings = self.candidate_title_vectors.size()[0]\n",
        "        self.candidate_title_embedding_dim = self.candidate_title_vectors.size()[1]\n",
        "\n",
        "        self.candidate_resume_vectors = candidate_resume.vocab.vectors\n",
        "        self.candidate_resume_num_embeddings = self.candidate_resume_vectors.size()[0]\n",
        "        self.candidate_resume_embedding_dim = self.candidate_resume_vectors.size()[1]\n",
        "\n",
        "        self.job_title_embeddings = nn.Embedding(self.job_title_num_embeddings, self.job_title_embedding_dim)\n",
        "        self.job_title_embeddings.weight.data.copy_(self.job_title_vectors)\n",
        "\n",
        "        self.job_description_embeddings = nn.Embedding(self.job_description_num_embeddings, self.job_description_embedding_dim)\n",
        "        self.job_description_embeddings.weight.data.copy_(self.job_description_vectors)\n",
        "\n",
        "        self.candidate_title_embeddings = nn.Embedding(self.candidate_title_num_embeddings, self.candidate_title_embedding_dim)\n",
        "        self.candidate_title_embeddings.weight.data.copy_(self.candidate_title_vectors)\n",
        "\n",
        "        self.candidate_resume_embeddings = nn.Embedding(self.candidate_resume_num_embeddings, self.candidate_resume_embedding_dim)\n",
        "        self.candidate_resume_embeddings.weight.data.copy_(self.candidate_resume_vectors)\n",
        "\n",
        "        self.lin1 = nn.Sequential(\n",
        "            nn.Dropout(p1),\n",
        "            nn.Linear(1200, 400),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.lin2 = nn.Sequential(\n",
        "            nn.Dropout(p2),\n",
        "            nn.Linear(400, 100),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.lin3 = nn.Sequential(\n",
        "            nn.Dropout(p3),\n",
        "            nn.Linear(100, 1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        job_title = data.job_title\n",
        "        job_description = data.job_description\n",
        "        candidate_title = data.candidate_title\n",
        "        candidate_resume = data.candidate_resume\n",
        "\n",
        "        numpy_job = job_title.cpu().data.numpy()\n",
        "        num_non_ones = np.count_nonzero(np.subtract(numpy_job, np.ones(numpy_job.shape)), axis=0)\n",
        "        num_non_ones = np.repeat(np.expand_dims(num_non_ones, 1), self.job_title_embedding_dim, 1)\n",
        "        num_non_ones = torch.tensor(num_non_ones).to(device).float()\n",
        "\n",
        "        job_title = self.job_title_embeddings(job_title)\n",
        "        job_title = torch.sum(job_title, 0).to(device) / num_non_ones\n",
        "\n",
        "        numpy_job = job_description.cpu().data.numpy()\n",
        "        num_non_ones = np.count_nonzero(np.subtract(numpy_job, np.ones(numpy_job.shape)), axis=0)\n",
        "        num_non_ones = np.repeat(np.expand_dims(num_non_ones, 1), self.job_description_embedding_dim, 1)\n",
        "        num_non_ones = torch.tensor(num_non_ones).to(device).float()\n",
        "\n",
        "        job_description = self.job_description_embeddings(job_description)\n",
        "        job_description = torch.sum(job_description, 0).to(device) / num_non_ones\n",
        "\n",
        "        numpy_candidate = candidate_title.cpu().data.numpy()\n",
        "        num_non_ones = np.count_nonzero(np.subtract(numpy_candidate, np.ones(numpy_candidate.shape)), axis=0)\n",
        "        num_non_ones = np.repeat(np.expand_dims(num_non_ones, 1), self.candidate_title_embedding_dim, 1)\n",
        "        num_non_ones = torch.tensor(num_non_ones).to(device).float()\n",
        "\n",
        "        candidate_title = self.candidate_title_embeddings(candidate_title)\n",
        "        candidate_title = torch.sum(candidate_title, 0).to(device) / num_non_ones\n",
        "\n",
        "        numpy_candidate = candidate_resume.cpu().data.numpy()\n",
        "        num_non_ones = np.count_nonzero(np.subtract(numpy_candidate, np.ones(numpy_candidate.shape)), axis=0)\n",
        "        num_non_ones = np.repeat(np.expand_dims(num_non_ones, 1), self.candidate_resume_embedding_dim, 1)\n",
        "        num_non_ones = torch.tensor(num_non_ones).to(device).float()\n",
        "\n",
        "        candidate_resume = self.candidate_resume_embeddings(candidate_resume)\n",
        "        candidate_resume = torch.sum(candidate_resume, 0).to(device) / num_non_ones\n",
        "\n",
        "        x = (job_title * job_description * candidate_title * candidate_resume).sum(1)\n",
        "\n",
        "        \"\"\"\n",
        "        catted = torch.cat([job_title, job_description, candidate_title, candidate_resume], dim=1)\n",
        "\n",
        "        x = self.lin1(catted)\n",
        "        x = self.lin2(x)\n",
        "        x = self.lin3(x)\n",
        "        \"\"\"\n",
        "        out = torch.sigmoid(x)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mF95z_C-hW3S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from types import SimpleNamespace\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "def talent_fox_train(train_iter, val_iter, net, optimizer, criterion, ratio, num_epochs=5):\n",
        "    net.train()\n",
        "    prev_epoch = 0\n",
        "    train_loss = []\n",
        "    train_accs = []\n",
        "    train_accs_pos = 0\n",
        "    train_sum = 0\n",
        "    val_res = []\n",
        "    for batch in train_iter:\n",
        "        (job_title, job_title_lengths) = batch.job_title\n",
        "        (job_description, job_description_lengths) = batch.job_description\n",
        "        (candidate_title, candidate_title_lengths) = batch.candidate_title\n",
        "        (candidate_resume, candidate_resume_lengths) = batch.candidate_resume\n",
        "        match_status = batch.match_status\n",
        "\n",
        "        net.train()\n",
        "\n",
        "        batch_sampling = {'job_title': job_title, 'job_description': job_description, 'candidate_title': candidate_title, 'candidate_resume': candidate_resume}\n",
        "        output = net(SimpleNamespace(**batch_sampling)).reshape(-1)\n",
        "        targets = match_status.float().to(device)\n",
        "        criterion.weight = weights(targets, ratio)\n",
        "        batch_loss = criterion(output, targets)\n",
        "\n",
        "        train_loss.append(get_numpy(batch_loss))\n",
        "        train_accs.append(accuracy_sigmoid(output, targets))\n",
        "        train_accs_pos += accuracy_talent(output, targets)\n",
        "        train_sum += sum_targets(targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        if train_iter.epoch != prev_epoch:\n",
        "            net.eval()\n",
        "            val_loss, val_accs, val_accs_pos, val_length, val_sum = 0, 0, 0, 0, 0\n",
        "\n",
        "            for val_batch in val_iter:\n",
        "                if val_iter.epoch != train_iter.epoch-1:\n",
        "                    break\n",
        "                (job_title, job_title_lengths) = val_batch.job_title\n",
        "                (job_description, job_description_lengths) = val_batch.job_description\n",
        "                (candidate_title, candidate_title_lengths) = val_batch.candidate_title\n",
        "                (candidate_resume, candidate_resume_lengths) = val_batch.candidate_resume\n",
        "                match_status = val_batch.match_status\n",
        "\n",
        "                batch_sampling = {'job_title': job_title, 'job_description': job_description,\n",
        "                                  'candidate_title': candidate_title, 'candidate_resume': candidate_resume}\n",
        "                val_output = net(SimpleNamespace(**batch_sampling)).reshape(-1)\n",
        "                val_target = match_status.float().to(device)\n",
        "                val_loss += criterion(val_output, val_target) * val_batch.batch_size\n",
        "                val_accs += accuracy_sigmoid(val_output, val_target) * val_batch.batch_size\n",
        "                val_accs_pos += accuracy_talent(val_output, val_target)\n",
        "                val_length += val_batch.batch_size\n",
        "                val_sum += sum_targets(val_target)\n",
        "\n",
        "            val_loss /= val_length\n",
        "            val_accs /= val_length\n",
        "            val_res.append(val_accs)\n",
        "\n",
        "            print(\n",
        "                \"Epoch {}: Train loss: {:.3f},  Train accs total: {:.3f}, Train accs positive: {:.3f}\"\n",
        "                    .format(train_iter.epoch, np.mean(train_loss), 1.0 - np.mean(train_accs), train_accs_pos/train_sum))\n",
        "            print(\n",
        "                \"          Validation loss: {:.3f}, Validation accs total: {:.3f}, Validation accs positive: {:.3f}\"\n",
        "                    .format(val_loss, 1.0 - val_accs, val_accs_pos/val_sum))\n",
        "            print()\n",
        "            train_loss = []\n",
        "            train_accs = []\n",
        "            train_accs_pos = 0\n",
        "            train_sum = 0\n",
        "            net.train()\n",
        "\n",
        "        prev_epoch = train_iter.epoch\n",
        "        if train_iter.epoch == num_epochs:\n",
        "            break\n",
        "\n",
        "def negative_sampling(users, docs, num_user):\n",
        "    if torch.cuda.is_available():\n",
        "        random_user = torch.tensor(\n",
        "        [randint(0, num_user) for _ in range(len(users))]\n",
        "        ).to(device)\n",
        "    else:\n",
        "        random_user = torch.tensor(\n",
        "            [randint(0, num_user-1) for _ in range(len(users))]\n",
        "        ).to(device)\n",
        "\n",
        "    author = torch.cat((users, random_user), 0).to(device)\n",
        "    doc_title = torch.cat((docs, docs), 1).to(device)\n",
        "\n",
        "    batch_with_negative_sampling = {'user': author, 'doc_title': doc_title}\n",
        "    return SimpleNamespace(**batch_with_negative_sampling)\n",
        "\n",
        "def plot_res(train_res, val_res, num_res):\n",
        "    x_vals = np.arange(num_res)\n",
        "    plt.figure()\n",
        "    plt.plot(x_vals, train_res, 'r', x_vals, val_res, 'b')\n",
        "    plt.legend(['Train Accucary', 'Validation Accuracy'])\n",
        "    plt.xlabel('Updates'), plt.ylabel('Acc')\n",
        "\n",
        "def accuracy_one_hot(output, target):\n",
        "    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n",
        "    correct_prediction = torch.eq(torch.max(output, 1)[1], target)\n",
        "    # averaging the one-hot encoded vector\n",
        "    return torch.mean(correct_prediction.float())\n",
        "\n",
        "def sum_targets(targets):\n",
        "    return torch.sum(targets)\n",
        "\n",
        "def accuracy_talent(output, targets):\n",
        "    correct_predictions = 0\n",
        "    for idx, val in enumerate(output):\n",
        "        if val > 0.5 and targets[idx] == torch.tensor(1.0):\n",
        "            correct_predictions += 1\n",
        "    return correct_predictions\n",
        "\n",
        "def accuracy_sigmoid(output, target):\n",
        "    return torch.mean(torch.abs(output - target).float()).to(device).data.numpy()\n",
        "\n",
        "\n",
        "def accuracy(output, target):\n",
        "    return torch.mean(torch.abs(torch.round(output) - target)).to(device).data.numpy()\n",
        "\n",
        "def weights(target, ratio):\n",
        "    weight = []\n",
        "    for val in target:\n",
        "        if val == torch.tensor(1.):\n",
        "            weight.append(ratio)\n",
        "        else:\n",
        "            weight.append(1.)\n",
        "    return torch.tensor(weight)\n",
        "\n",
        "def print_params(net):\n",
        "    for name, param in net.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(name, param.data)\n",
        "\n",
        "\n",
        "def get_numpy(loss):\n",
        "    return loss.to(device).data.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KpVwL5MTLpDS",
        "colab_type": "code",
        "outputId": "e8b008df-99b9-453c-a7f9-fa514e86e067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2635
        }
      },
      "cell_type": "code",
      "source": [
        "from torch import optim, nn\n",
        "\n",
        "tf = TalentFox(batch_size=100)\n",
        "\n",
        "train_iter = tf.train_iter\n",
        "val_iter = tf.validation_iter\n",
        "\n",
        "job_title = tf.job_title\n",
        "job_description = tf.job_description\n",
        "candidate_title = tf.candidate_title\n",
        "candidate_resume = tf.candidate_resume\n",
        "\n",
        "ratio = (train_iter.dataset.fields['match_status'].vocab.freqs['0']/train_iter.dataset.fields['match_status'].vocab.freqs['1'])\n",
        "\n",
        "net = TalentNetExperimental(job_title=job_title, job_description=job_description, candidate_title=candidate_title, candidate_resume=candidate_resume).to(device)\n",
        "opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "talent_fox_train(train_iter=train_iter, val_iter=val_iter, net=net, optimizer=opt, criterion=criterion, ratio=ratio, num_epochs=1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cpu\n",
            "Epoch 1: Train loss: 1.373,  Train accs total: 0.470, Train accs positive: 0.909\n",
            "          Validation loss: 1.701, Validation accs total: 0.472, Validation accs positive: 0.909\n",
            "\n",
            "Epoch 2: Train loss: 1.299,  Train accs total: 0.483, Train accs positive: 0.967\n",
            "          Validation loss: 1.081, Validation accs total: 0.487, Validation accs positive: 0.909\n",
            "\n",
            "Epoch 3: Train loss: 1.270,  Train accs total: 0.499, Train accs positive: 0.950\n",
            "          Validation loss: 1.227, Validation accs total: 0.498, Validation accs positive: 0.873\n",
            "\n",
            "Epoch 4: Train loss: 1.231,  Train accs total: 0.511, Train accs positive: 0.942\n",
            "          Validation loss: 1.233, Validation accs total: 0.515, Validation accs positive: 0.745\n",
            "\n",
            "Epoch 5: Train loss: 1.191,  Train accs total: 0.532, Train accs positive: 0.880\n",
            "          Validation loss: 1.083, Validation accs total: 0.542, Validation accs positive: 0.545\n",
            "\n",
            "Epoch 6: Train loss: 1.147,  Train accs total: 0.557, Train accs positive: 0.880\n",
            "          Validation loss: 1.183, Validation accs total: 0.554, Validation accs positive: 0.527\n",
            "\n",
            "Epoch 7: Train loss: 1.079,  Train accs total: 0.577, Train accs positive: 0.892\n",
            "          Validation loss: 0.608, Validation accs total: 0.582, Validation accs positive: 0.455\n",
            "\n",
            "Epoch 8: Train loss: 1.018,  Train accs total: 0.605, Train accs positive: 0.913\n",
            "          Validation loss: 1.363, Validation accs total: 0.588, Validation accs positive: 0.509\n",
            "\n",
            "Epoch 9: Train loss: 0.968,  Train accs total: 0.620, Train accs positive: 0.896\n",
            "          Validation loss: 1.113, Validation accs total: 0.624, Validation accs positive: 0.345\n",
            "\n",
            "Epoch 10: Train loss: 0.898,  Train accs total: 0.646, Train accs positive: 0.905\n",
            "          Validation loss: 1.363, Validation accs total: 0.639, Validation accs positive: 0.345\n",
            "\n",
            "Epoch 11: Train loss: 0.979,  Train accs total: 0.648, Train accs positive: 0.934\n",
            "          Validation loss: 0.878, Validation accs total: 0.646, Validation accs positive: 0.364\n",
            "\n",
            "Epoch 12: Train loss: 0.814,  Train accs total: 0.672, Train accs positive: 0.946\n",
            "          Validation loss: 1.009, Validation accs total: 0.658, Validation accs positive: 0.345\n",
            "\n",
            "Epoch 13: Train loss: 0.744,  Train accs total: 0.691, Train accs positive: 0.971\n",
            "          Validation loss: 0.968, Validation accs total: 0.678, Validation accs positive: 0.345\n",
            "\n",
            "Epoch 14: Train loss: 0.683,  Train accs total: 0.713, Train accs positive: 0.967\n",
            "          Validation loss: 1.411, Validation accs total: 0.695, Validation accs positive: 0.291\n",
            "\n",
            "Epoch 15: Train loss: 0.643,  Train accs total: 0.725, Train accs positive: 0.979\n",
            "          Validation loss: 0.954, Validation accs total: 0.704, Validation accs positive: 0.309\n",
            "\n",
            "Epoch 16: Train loss: 0.595,  Train accs total: 0.744, Train accs positive: 0.983\n",
            "          Validation loss: 0.923, Validation accs total: 0.729, Validation accs positive: 0.236\n",
            "\n",
            "Epoch 17: Train loss: 0.547,  Train accs total: 0.768, Train accs positive: 0.975\n",
            "          Validation loss: 2.159, Validation accs total: 0.745, Validation accs positive: 0.273\n",
            "\n",
            "Epoch 18: Train loss: 0.600,  Train accs total: 0.770, Train accs positive: 0.983\n",
            "          Validation loss: 0.563, Validation accs total: 0.744, Validation accs positive: 0.273\n",
            "\n",
            "Epoch 19: Train loss: 0.523,  Train accs total: 0.775, Train accs positive: 0.979\n",
            "          Validation loss: 1.560, Validation accs total: 0.751, Validation accs positive: 0.273\n",
            "\n",
            "Epoch 20: Train loss: 0.445,  Train accs total: 0.798, Train accs positive: 0.996\n",
            "          Validation loss: 2.050, Validation accs total: 0.771, Validation accs positive: 0.255\n",
            "\n",
            "Epoch 21: Train loss: 0.414,  Train accs total: 0.817, Train accs positive: 0.979\n",
            "          Validation loss: 1.685, Validation accs total: 0.784, Validation accs positive: 0.255\n",
            "\n",
            "Epoch 22: Train loss: 0.388,  Train accs total: 0.825, Train accs positive: 0.996\n",
            "          Validation loss: 1.169, Validation accs total: 0.789, Validation accs positive: 0.273\n",
            "\n",
            "Epoch 23: Train loss: 0.356,  Train accs total: 0.837, Train accs positive: 0.996\n",
            "          Validation loss: 0.964, Validation accs total: 0.802, Validation accs positive: 0.273\n",
            "\n",
            "Epoch 24: Train loss: 0.317,  Train accs total: 0.853, Train accs positive: 0.992\n",
            "          Validation loss: 0.762, Validation accs total: 0.808, Validation accs positive: 0.273\n",
            "\n",
            "Epoch 25: Train loss: 0.292,  Train accs total: 0.864, Train accs positive: 1.000\n",
            "          Validation loss: 0.756, Validation accs total: 0.825, Validation accs positive: 0.236\n",
            "\n",
            "Epoch 26: Train loss: 0.321,  Train accs total: 0.858, Train accs positive: 0.996\n",
            "          Validation loss: 0.841, Validation accs total: 0.801, Validation accs positive: 0.291\n",
            "\n",
            "Epoch 27: Train loss: 0.288,  Train accs total: 0.870, Train accs positive: 0.996\n",
            "          Validation loss: 0.589, Validation accs total: 0.824, Validation accs positive: 0.255\n",
            "\n",
            "Epoch 28: Train loss: 0.262,  Train accs total: 0.882, Train accs positive: 0.996\n",
            "          Validation loss: 0.984, Validation accs total: 0.834, Validation accs positive: 0.255\n",
            "\n",
            "Epoch 29: Train loss: 0.321,  Train accs total: 0.890, Train accs positive: 0.996\n",
            "          Validation loss: 1.054, Validation accs total: 0.816, Validation accs positive: 0.273\n",
            "\n",
            "Epoch 30: Train loss: 0.265,  Train accs total: 0.880, Train accs positive: 1.000\n",
            "          Validation loss: 0.943, Validation accs total: 0.825, Validation accs positive: 0.236\n",
            "\n",
            "Epoch 31: Train loss: 0.231,  Train accs total: 0.896, Train accs positive: 1.000\n",
            "          Validation loss: 0.852, Validation accs total: 0.836, Validation accs positive: 0.218\n",
            "\n",
            "Epoch 32: Train loss: 0.209,  Train accs total: 0.904, Train accs positive: 1.000\n",
            "          Validation loss: 0.857, Validation accs total: 0.846, Validation accs positive: 0.182\n",
            "\n",
            "Epoch 33: Train loss: 0.203,  Train accs total: 0.908, Train accs positive: 1.000\n",
            "          Validation loss: 0.439, Validation accs total: 0.852, Validation accs positive: 0.182\n",
            "\n",
            "Epoch 34: Train loss: 0.195,  Train accs total: 0.914, Train accs positive: 1.000\n",
            "          Validation loss: 1.005, Validation accs total: 0.857, Validation accs positive: 0.182\n",
            "\n",
            "Epoch 35: Train loss: 0.188,  Train accs total: 0.917, Train accs positive: 1.000\n",
            "          Validation loss: 0.980, Validation accs total: 0.858, Validation accs positive: 0.182\n",
            "\n",
            "Epoch 36: Train loss: 0.173,  Train accs total: 0.923, Train accs positive: 1.000\n",
            "          Validation loss: 1.106, Validation accs total: 0.864, Validation accs positive: 0.200\n",
            "\n",
            "Epoch 37: Train loss: 0.165,  Train accs total: 0.926, Train accs positive: 1.000\n",
            "          Validation loss: 0.553, Validation accs total: 0.865, Validation accs positive: 0.200\n",
            "\n",
            "Epoch 38: Train loss: 0.161,  Train accs total: 0.928, Train accs positive: 1.000\n",
            "          Validation loss: 0.752, Validation accs total: 0.870, Validation accs positive: 0.182\n",
            "\n",
            "Epoch 39: Train loss: 0.154,  Train accs total: 0.929, Train accs positive: 1.000\n",
            "          Validation loss: 1.138, Validation accs total: 0.873, Validation accs positive: 0.182\n",
            "\n",
            "Epoch 40: Train loss: 0.145,  Train accs total: 0.935, Train accs positive: 1.000\n",
            "          Validation loss: 0.638, Validation accs total: 0.876, Validation accs positive: 0.182\n",
            "\n",
            "Epoch 41: Train loss: 0.333,  Train accs total: 0.934, Train accs positive: 0.996\n",
            "          Validation loss: 0.611, Validation accs total: 0.875, Validation accs positive: 0.182\n",
            "\n",
            "Epoch 42: Train loss: 0.143,  Train accs total: 0.937, Train accs positive: 1.000\n",
            "          Validation loss: 0.658, Validation accs total: 0.879, Validation accs positive: 0.182\n",
            "\n",
            "Epoch 43: Train loss: 0.134,  Train accs total: 0.941, Train accs positive: 1.000\n",
            "          Validation loss: 1.039, Validation accs total: 0.881, Validation accs positive: 0.182\n",
            "\n",
            "Epoch 44: Train loss: 0.125,  Train accs total: 0.942, Train accs positive: 1.000\n",
            "          Validation loss: 0.405, Validation accs total: 0.883, Validation accs positive: 0.182\n",
            "\n",
            "Epoch 45: Train loss: 0.137,  Train accs total: 0.939, Train accs positive: 0.996\n",
            "          Validation loss: 0.567, Validation accs total: 0.877, Validation accs positive: 0.200\n",
            "\n",
            "Epoch 46: Train loss: 0.126,  Train accs total: 0.942, Train accs positive: 1.000\n",
            "          Validation loss: 0.791, Validation accs total: 0.885, Validation accs positive: 0.164\n",
            "\n",
            "Epoch 47: Train loss: 0.141,  Train accs total: 0.944, Train accs positive: 0.996\n",
            "          Validation loss: 0.440, Validation accs total: 0.877, Validation accs positive: 0.182\n",
            "\n",
            "Epoch 48: Train loss: 0.117,  Train accs total: 0.948, Train accs positive: 0.996\n",
            "          Validation loss: 0.852, Validation accs total: 0.881, Validation accs positive: 0.182\n",
            "\n",
            "Epoch 49: Train loss: 0.222,  Train accs total: 0.939, Train accs positive: 0.992\n",
            "          Validation loss: 1.358, Validation accs total: 0.869, Validation accs positive: 0.200\n",
            "\n",
            "Epoch 50: Train loss: 0.119,  Train accs total: 0.948, Train accs positive: 1.000\n",
            "          Validation loss: 0.472, Validation accs total: 0.886, Validation accs positive: 0.164\n",
            "\n",
            "Epoch 51: Train loss: 0.113,  Train accs total: 0.951, Train accs positive: 1.000\n",
            "          Validation loss: 0.670, Validation accs total: 0.888, Validation accs positive: 0.164\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}